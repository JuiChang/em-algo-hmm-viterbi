{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM Algorithm - (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the training & testing dataset\n",
    "* the first 500 data belong to class1, the last 500 data belong to class2 (both in the training and the testing set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_p1():\n",
    "    m1 = np.array([1.25, 1.25])\n",
    "    m2 = np.array([2.75, 2.75])\n",
    "    m3 = np.array([2, 1.6])\n",
    "    s1 = 0.1 * np.identity(2)\n",
    "    s2 = 0.2 * np.identity(2)\n",
    "    s3 = 0.3 * np.identity(2)\n",
    "    \n",
    "    norm1 = multivariate_normal(mean=m1, cov=s1)\n",
    "    norm2 = multivariate_normal(mean=m2, cov=s2)\n",
    "    norm3 = multivariate_normal(mean=m3, cov=s3)\n",
    "    \n",
    "    dataset = np.zeros((2, 500)) # each column corresponds to a data\n",
    "    \n",
    "    for i in range(500):\n",
    "        decide_pdf = np.random.randint(0, 10)\n",
    "        if 0 <= decide_pdf <= 3:\n",
    "            dataset[:, i] = norm1.rvs()\n",
    "        elif 4 <= decide_pdf <= 7:\n",
    "            dataset[:, i] = norm2.rvs()\n",
    "        else:\n",
    "            dataset[:, i] = norm3.rvs()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def generate_dataset_p2():\n",
    "    m1 = np.array([1.25, 2.75])\n",
    "    m2 = np.array([2.75, 1.25])\n",
    "    m3 = np.array([4, 6])\n",
    "    s1 = 0.1 * np.identity(2)\n",
    "    s2 = 0.2 * np.identity(2)\n",
    "    s3 = 0.3 * np.identity(2)\n",
    "    \n",
    "    norm1 = multivariate_normal(mean=m1, cov=s1)\n",
    "    norm2 = multivariate_normal(mean=m2, cov=s2)\n",
    "    norm3 = multivariate_normal(mean=m3, cov=s3)\n",
    "    \n",
    "    dataset = np.zeros((2, 500)) # each column corresponds to a data\n",
    "    \n",
    "    for i in range(500):\n",
    "        decide_pdf = np.random.randint(0, 10)\n",
    "        if 0 <= decide_pdf <= 1:\n",
    "            dataset[:, i] = norm1.rvs()\n",
    "        elif 2 <= decide_pdf <= 4:\n",
    "            dataset[:, i] = norm2.rvs()\n",
    "        else:\n",
    "            dataset[:, i] = norm3.rvs()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.concatenate((generate_dataset_p1(), generate_dataset_p2()), axis=1)\n",
    "test = np.concatenate((generate_dataset_p1(), generate_dataset_p2()), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions of EM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf(X, mu_l, cov_l):\n",
    "    norm = multivariate_normal(mean=mu_l, cov=cov_l, allow_singular=True)\n",
    "    return norm.pdf(X)\n",
    "\n",
    "\n",
    "def e_step(dataset, alpha, mu, cov, expect, J):\n",
    "    \n",
    "    for l in range(J):\n",
    "        numera = alpha[l] * pdf(np.transpose(dataset), mu[:, l], cov[:, :, l])\n",
    "\n",
    "        denomi = 0\n",
    "        for iter_l in range(J):\n",
    "            denomi += alpha[iter_l] * pdf(np.transpose(dataset), mu[:, iter_l], cov[:, :, iter_l])\n",
    "\n",
    "        expect[l, :] = numera / denomi\n",
    "        \n",
    "    return expect\n",
    "            \n",
    "        \n",
    "def m_step(dataset, alpha, mu, cov, expect, J):\n",
    "    \n",
    "    # calculate new alpha\n",
    "    alpha = np.sum(expect, axis=1) / dataset.shape[1]\n",
    "    \n",
    "    # calculate new mu\n",
    "    for l in range(J):\n",
    "        # expect[l]: probability density of each data of model l\n",
    "        numera = np.sum(expect[l] * dataset, axis=1)\n",
    "        denomi = np.sum(expect[l])\n",
    "        mu[:, l] = numera / denomi\n",
    "    \n",
    "    # calculate new cov\n",
    "    for l in range(J):\n",
    "        \n",
    "        numera = np.zeros((2, 2))\n",
    "        for i in range(dataset.shape[1]):\n",
    "            diff_vec = np.reshape(dataset[:, i] - mu[:, l], (2, 1))\n",
    "            numera += expect[l, i] * diff_vec.dot(np.transpose(diff_vec))\n",
    "        \n",
    "        denomi = np.sum(expect[l])\n",
    "        \n",
    "        cov[:, :, l] = numera / denomi\n",
    "        \n",
    "    return alpha, mu, cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) - (1):   \n",
    "estimate p1(x) and p2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters of the three models of the class 3 after training:\n",
      "em iteration i = 199\n",
      "alpha_c1 0 = 0.36715301760429214\n",
      "alpha_c1 1 = 0.46691762390717373\n",
      "alpha_c1 2 = 0.16592935848853416\n",
      "mu_c1 0 = [1.64782109 1.40921055]\n",
      "mu_c1 1 = [2.71052353 2.71197188]\n",
      "mu_c1 2 = [1.18349451 1.24541188]\n",
      "cov_c1 0 =\n",
      " [[0.27340815 0.01332311]\n",
      " [0.01332311 0.21315136]]\n",
      "cov_c1 1 =\n",
      " [[ 0.19121626 -0.00193205]\n",
      " [-0.00193205  0.20183036]]\n",
      "cov_c1 2 =\n",
      " [[0.06035753 0.0096439 ]\n",
      " [0.0096439  0.04109751]]\n",
      "\n",
      "\n",
      "parameters of the three models of the class 2 after training:\n",
      "em iteration i = 199\n",
      "alpha_c2 0 = 0.29448508185713\n",
      "alpha_c2 1 = 0.4840000002633138\n",
      "alpha_c2 2 = 0.2215149178795562\n",
      "mu_c2 0 = [2.73012045 1.22839123]\n",
      "mu_c2 1 = [4.01305981 6.01019344]\n",
      "mu_c2 2 = [1.32261869 2.72750678]\n",
      "cov_c2 0 =\n",
      " [[0.19296048 0.0045372 ]\n",
      " [0.0045372  0.21092971]]\n",
      "cov_c2 1 =\n",
      " [[0.30814225 0.00291631]\n",
      " [0.00291631 0.26067554]]\n",
      "cov_c2 2 =\n",
      " [[ 0.10895812 -0.01332066]\n",
      " [-0.01332066  0.11666792]]\n"
     ]
    }
   ],
   "source": [
    "J = 3\n",
    "    \n",
    "#### define/initialize the variables to estimate\n",
    "# parameters of class 1\n",
    "alpha_c1 = np.zeros(J) # each element corresponds to a model\n",
    "alpha_c1[:] = 1 / J\n",
    "\n",
    "mu_c1 = np.random.rand(2, J) # each column corresponds to a model\n",
    "mu_c1 *= J\n",
    "\n",
    "cov_c1 = np.zeros((2, 2, J))\n",
    "for i in range(J):\n",
    "    cov_c1[:, :, i] = random.uniform(0, 1) * np.identity(2)\n",
    "\n",
    "expect_c1 = np.zeros((J, 500)) # each column corresponds to a data\n",
    "\n",
    "# parameters of class 2\n",
    "alpha_c2 = np.zeros(J)\n",
    "alpha_c2[:] = 1 / J\n",
    "\n",
    "mu_c2 = np.random.rand(2, J)\n",
    "mu_c2 *= J\n",
    "\n",
    "cov_c2 = np.zeros((2, 2, J))\n",
    "for i in range(J):\n",
    "    cov_c2[:, :, i] = random.uniform(0, 1) * np.identity(2)\n",
    "\n",
    "expect_c2 = np.zeros((J, 500))\n",
    "\n",
    "\n",
    "#### train for class 1 with the training data which belong to class 1\n",
    "for i in range(200):\n",
    "    expect_c1 = e_step(train[:, :500], alpha_c1, mu_c1, cov_c1, expect_c1, J)\n",
    "    alpha_c1, mu_c1, cov_c1 = m_step(train[:, :500], alpha_c1, mu_c1, cov_c1, expect_c1, J)\n",
    "    if i == 199:\n",
    "        print('parameters of the three models of the class 3 after training:')\n",
    "        print('em iteration i =', i)\n",
    "        for k in range(J):\n",
    "            print('alpha_c1', k, '=', alpha_c1[k])\n",
    "        for k in range(J):\n",
    "            print('mu_c1', k, '=', mu_c1[:, k])\n",
    "        for k in range(J):\n",
    "            print('cov_c1', k, '=\\n', cov_c1[:, :, k])\n",
    "\n",
    "#### train for class 2 with the training data which belong to class 2\n",
    "for i in range(200):\n",
    "    expect_c2 = e_step(train[:, 500:], alpha_c2, mu_c2, cov_c2, expect_c2, J)\n",
    "    alpha_c2, mu_c2, cov_c2 = m_step(train[:, 500:], alpha_c2, mu_c2, cov_c2, expect_c2, J)\n",
    "    if i == 199:\n",
    "        print('\\n\\nparameters of the three models of the class 2 after training:')\n",
    "        print('em iteration i =', i)\n",
    "        for k in range(J):\n",
    "            print('alpha_c2', k, '=', alpha_c2[k])\n",
    "        for k in range(J):\n",
    "            print('mu_c2', k, '=', mu_c2[:, k])\n",
    "        for k in range(J):\n",
    "            print('cov_c2', k, '=\\n', cov_c2[:, :, k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) - (2)  \n",
    "#### Train and test, loop by different J\n",
    "* define/initialize the variables to estimate\n",
    "* train\n",
    "* test  \n",
    "p.s. when J is large (about 10~20), the below code may enconter ValueError about inf and NaNs, I guess it's because of some extremely small values in alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J = 1 , accuracy = 0.852\n",
      "J = 2 , accuracy = 0.902\n",
      "J = 3 , accuracy = 0.913\n",
      "J = 4 , accuracy = 0.916\n",
      "J = 5 , accuracy = 0.913\n",
      "J = 6 , accuracy = 0.917\n",
      "J = 7 , accuracy = 0.911\n",
      "J = 8 , accuracy = 0.908\n",
      "J = 9 , accuracy = 0.911\n"
     ]
    }
   ],
   "source": [
    "for J in range(1, 11):\n",
    "    \n",
    "    #### define/initialize the variables to estimate\n",
    "    # parameters of class 1\n",
    "    alpha_c1 = np.zeros(J) # each element corresponds to a model\n",
    "    alpha_c1[:] = 1 / J\n",
    "\n",
    "    mu_c1 = np.random.rand(2, J) # each column corresponds to a model\n",
    "    mu_c1 *= J\n",
    "\n",
    "    cov_c1 = np.zeros((2, 2, J))\n",
    "    for i in range(J):\n",
    "        cov_c1[:, :, i] = random.uniform(0, 1) * np.identity(2)\n",
    "\n",
    "    expect_c1 = np.zeros((J, 500)) # each column corresponds to a data\n",
    "\n",
    "    # parameters of class 2\n",
    "    alpha_c2 = np.zeros(J)\n",
    "    alpha_c2[:] = 1 / J\n",
    "\n",
    "    mu_c2 = np.random.rand(2, J)\n",
    "    mu_c2 *= J\n",
    "\n",
    "    cov_c2 = np.zeros((2, 2, J))\n",
    "    for i in range(J):\n",
    "        cov_c2[:, :, i] = random.uniform(0, 1) * np.identity(2)\n",
    "\n",
    "    expect_c2 = np.zeros((J, 500))\n",
    "\n",
    "    \n",
    "    #### train for class 1 with the training data which belong to class 1\n",
    "    for i in range(200):\n",
    "        expect_c1 = e_step(train[:, :500], alpha_c1, mu_c1, cov_c1, expect_c1, J)\n",
    "        alpha_c1, mu_c1, cov_c1 = m_step(train[:, :500], alpha_c1, mu_c1, cov_c1, expect_c1, J)\n",
    "#         if i == 199:\n",
    "#             print('em iteration i =', i)\n",
    "#             for k in range(J):\n",
    "#                 print('alpha_c1', k, '=', alpha_c1[k])\n",
    "#             for k in range(J):\n",
    "#                 print('mu_c1', k, '=', mu_c1[:, k])\n",
    "#             for k in range(J):\n",
    "#                 print('cov_c1', k, '=\\n', cov_c1[:, :, k])\n",
    "\n",
    "    #### train for class 2 with the training data which belong to class 2\n",
    "    for i in range(200):\n",
    "        expect_c2 = e_step(train[:, 500:], alpha_c2, mu_c2, cov_c2, expect_c2, J)\n",
    "        alpha_c2, mu_c2, cov_c2 = m_step(train[:, 500:], alpha_c2, mu_c2, cov_c2, expect_c2, J)\n",
    "#         if i == 199:\n",
    "#             print('em iteration i =', i)\n",
    "#             for k in range(J):\n",
    "#                 print('alpha_c2', k, '=', alpha_c2[k])\n",
    "#             for k in range(J):\n",
    "#                 print('mu_c2', k, '=', mu_c2[:, k])\n",
    "#             for k in range(J):\n",
    "#                 print('cov_c2', k, '=\\n', cov_c2[:, :, k])\n",
    "\n",
    "    #### test\n",
    "    # calculate likehood correspond to class 1 for each data in the test set\n",
    "    value_c1 = np.zeros(1000)\n",
    "    for i in range(J):\n",
    "        value_c1 = value_c1 + alpha_c1[i] * pdf(np.transpose(test), mu_c1[:, i], cov_c1[:, :, i])\n",
    "\n",
    "    # calculate likehood correspond to class 1 for each data in the test set\n",
    "    value_c2 = np.zeros(1000)\n",
    "    for i in range(J):\n",
    "        value_c2 = value_c2 + alpha_c2[i] * pdf(np.transpose(test), mu_c2[:, i], cov_c2[:, :, i])\n",
    "\n",
    "    # because the priors of the two classes are the same (500/1000, observed from the training data), \n",
    "    # so we can simply compare the likelihoods of the two classes while classifying\n",
    "    pred_as_c1 = value_c1 >= value_c2\n",
    "\n",
    "    print('J =', J, ', accuracy =', (sum(pred_as_c1[:500]) + sum(~pred_as_c1[500:])) / 1000)\n",
    "#     print('----------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The test accuracy with J = 1 is much lower than others (i.e. the classification error is much higher than others).\n",
    "* The models estimated with J = 6 has the highest test accuracy (lowest classification error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pr_hw)",
   "language": "python",
   "name": "pr_hw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
